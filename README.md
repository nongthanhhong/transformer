# **Transformer**
Implement Transformer with pytorch, using for Eng-Vi translation

[Attention Is All You Need](https://arxiv.org/abs/1706.03762)

[On Layer Normalization in the Transformer Architecture](https://arxiv.org/abs/2002.04745)

[Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training](https://arxiv.org/abs/2305.14342)
